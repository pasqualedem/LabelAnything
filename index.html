<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Label Anything is a few-shot semantic segmentation model working with different types of support set annotations: points, boxes, and masks.">
    <meta name="keywords" content="Label Anything, LA">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Label Anything</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/swiper.css">
    <!-- <link rel="stylesheet" href="./static/css/bulma-carousel.min.css"> -->
    <!-- <link rel="stylesheet" href="./static/css/bulma-slider.min.css"> -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.css" />
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.js"></script>
    <!-- <script src="./static/js/bulma-slider.min.js"></script> -->
</head>

<body>

    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
                <a class="navbar-item" href="https://nicolafan.github.io">
                    <span class="icon">
                        <i class="fas fa-home"></i>
                    </span>
                </a>

                <div class="navbar-item has-dropdown is-hoverable">
                    <a class="navbar-link">
                        More Research
                    </a>
                    <div class="navbar-dropdown">
                        <a class="navbar-item" href="https://pasqualedem.github.io/">
                            Pasquale De Marinis' Website
                        </a>
                        <a class="navbar-item" href="https://sites.google.com/site/cilabuniba/home">
                            CILab's Website
                        </a>
                    </div>
                </div>
            </div>

        </div>
    </nav>

    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Label Anything: Multi-Class Few-Shot Semantic
                            Segmentation with Visual Prompts</h1>
                        <h2 class="title is-5 publication-title">European Conference on Artificial Intelligence (ECAI)
                            2025</h2>
                        <div class="is-size-5 publication-authors">
                            <span class="author-block">
                                <a href="https://pasqualedem.github.io/">Pasquale De Marinis</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://nicolafan.github.io/">Nicola Fanelli</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/raffaele-scaringi-7941b2199">Raffaele
                                    Scaringi</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.linkedin.com/in/emanuele-colonna-60b876225">Emanuele
                                    Colonna</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=Se2mLvIAAAAJ">Giuseppe
                                    Fiameni</a><sup>2</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://www.gennarovessio.com//">Gennaro Vessio</a><sup>1</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://sites.google.com/site/cilabuniba/people/giovanna-castellano">Giovanna
                                    Castellano</a><sup>1</sup>
                            </span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>University of Bari Aldo Moro,</span>
                            <span class="author-block"><sup>2</sup>NVIDIA</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/pdf/2407.02075"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fas fa-file-pdf"></i>
                                        </span>
                                        <span>Paper</span>
                                    </a>
                                </span>
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2407.02075"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Video Link. -->
                                <!-- <span class="link-block">
                                    <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-youtube"></i>
                                        </span>
                                        <span>Video</span>
                                    </a>
                                </span> -->
                                <!-- Code Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/pasqualedem/LabelAnything"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <!-- <span class="link-block">
                                    <a href="https://github.com/google/nerfies/releases/tag/0.1"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="far fa-images"></i>
                                        </span>
                                        <span>Data</span>
                                    </a> -->
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
            <div class="hero-body">
                <img id="teaser-img" src="./static/images/la.png" alt="Label Anything teaser"
                    style="width:100%; height:auto;" />
                <h2 class="subtitle has-text-centered">
                    <span class="dnerf">Label Anything</span> performs few-shot semantic segmentation over query images,
                    segmenting objects of interest specified by points, boxes, or masks over an arbitrarily large set of
                    support images.
                </h2>
            </div>
        </div>
    </section>


    <!-- <section class="hero is-light is-small">
        <div class="hero-body">
            <div class="container">
                <div id="results-carousel" class="carousel results-carousel">
                    <div class="item item-steve">
                    <div class="item">
                        <img src="./static/images/LAexamples_1.png"
                            alt="Label Anything example 1" />
                    </div>
                    </div>
                    <div class="item item-chair-tp">
                        <img src="./static/images/LAexamples_2.png"
                            alt="Label Anything example 2" />
                    </div>
                    <div class="item item-shiba">
                        <img src="./static/images/LAexamples_3.png"
                            alt="Label Anything example 3" />
                    </div>
                    <div class="item item-fullbody">
                        <img src="./static/images/LAexamples_4.png"
                            alt="Label Anything example 4" />
                    </div>
                </div>
            </div>
        </div>
    </section> -->

    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Few-shot semantic segmentation aims to segment objects from previously unseen classes using
                            only a limited number of labeled examples. In this paper, we introduce Label Anything, a
                            novel transformer-based architecture designed for multi-prompt, multi-way few-shot semantic
                            segmentation. Our approach leverages diverse visual prompts—points, bounding boxes, and
                            masks—to create a highly flexible and generalizable framework that significantly reduces
                            annotation burden while maintaining high accuracy.
                            Label Anything makes three key contributions: (i) we introduce a new task
                            formulation that relaxes conventional few-shot segmentation constraints by supporting
                            various types of prompts, multi-class classification, and enabling multiple prompts within a
                            single image; (ii) we propose a novel architecture based on transformers and
                            attention mechanisms, eliminating dependency on convolutional networks; and (iii)
                            we design a versatile training procedure allowing our model to operate seamlessly across
                            different N-way K-shot and prompt-type configurations with a single trained model.
                            Our extensive experimental evaluation on the widely used COCO-20i benchmark demonstrates
                            that Label Anything achieves state-of-the-art performance among existing multi-way few-shot
                            segmentation methods, while significantly outperforming leading single-class models when
                            evaluated in multi-class settings. Code and trained models are available at our <a href="
                            https://github.com/pasqualedem/LabelAnything">GitHub</a>.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Abstract. -->

            <!-- Paper video. -->
            <!-- <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Video</h2>
                    <div class="publication-video">
                        <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0" frameborder="0"
                            allow="autoplay; encrypted-media" allowfullscreen></iframe>
                    </div>
                </div>
            </div> -->
            <!--/ Paper video. -->
        </div>
    </section>

    <section class="hero is-light is-small">
        <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered has-text-centered">
                <div class="column is-full-width">
                <h2 class="title is-3">Gallery</h2><br>
            <div class="container">
                <div class="swiper swiper-container">
                    <div class="swiper-wrapper">
                        <div class="swiper-slide">
                            <img src="./static/images/LAexamples_1.svg" alt="Label Anything example 1" />
                        </div>
                        <div class="swiper-slide">
                            <img src="./static/images/LAexamples_2.svg" alt="Label Anything example 2" />
                        </div>
                        <div class="swiper-slide">
                            <img src="./static/images/LAexamples_3.svg" alt="Label Anything example 3" />
                        </div>
                        <div class="swiper-slide">
                            <img src="./static/images/LAexamples_4.svg" alt="Label Anything example 4" />
                        </div>
                    </div>
                    <!-- Pagination -->
                    <div class="swiper-pagination"></div>
                    <div class="swiper-button-next"></div>
                    <div class="swiper-button-prev"></div>
                </div>
            </div>
        </div>
        </div>
            </div>
            </div>
            </div>
    </section>

    <section class="section">
        <div class="container is-max-desktop">

            <!-- Explanation. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">How it works</h2>

                    <!-- Prototype Learning through Prompting. -->
                    <h3 class="title is-4">Prototype Learning through Prompting</h3>
                    <div class="content has-text-justified">
                        <p>
                            Label Anything learns to segment objects by learning a prototype for each class specified by
                            a visual prompt. It first fuses support image features with dense and sparse prompt
                            embeddings using a two-way attention mechanism, producing enriched class-specific
                            representations. These are then pooled into class-example embeddings and refined via a
                            self-attention mixer, which aggregates them into a single class prototype capturing the
                            shared semantics across support examples, to guide segmentation in the query image.
                        </p>
                        <video id="encoding" autoplay muted loop playsinline height="100%">
                            <source src="./static/videos/LA_PromptEncoding.mp4" type="video/mp4">
                        </video>
                    </div>
                    <!--/ Prototype Learning through Prompting. -->

                    <!-- Mask Decoding. -->
                    <h3 class="title is-4">Masks Decoding</h3>
                    <div class="content has-text-justified">
                        <p>
                            Label Anything decodes segmentation masks by matching learned class prototypes to the query
                            image features. A two-way attention mechanism enables mutual interaction between the
                            prototypes and query features, allowing class-specific patterns to be transferred to the
                            query representation. The query features are then upsampled, spatially refined, and
                            projected to match the prototype dimensions, after which segmentation masks are generated
                            via a dot product between the transformed query features and the class prototypes.
                        </p>
                    </div>
                    <div class="content has-text-centered">
                        <video id="replay-video" autoplay muted loop playsinline width="100%">
                            <source src="./static/videos/LA_MaskDecoding.mp4" type="video/mp4">
                        </video>
                    </div>
                    <!--/ Mask Decoding. -->

                </div>
            </div>
            <!--/ Explanation -->


            <!-- Concurrent Work. -->
            <!-- <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Related Links</h2>

                    <div class="content has-text-justified">
                        <p>
                            There's a lot of excellent work that was introduced around the same time as ours.
                        </p>
                        <p>
                            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a>
                            introduces an idea similar to our windowed position encoding for coarse-to-fine
                            optimization.
                        </p>
                        <p>
                            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a
                                href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
                            both use deformation fields to model non-rigid scenes.
                        </p>
                        <p>
                            Some works model videos with a NeRF by directly modulating the density, such as <a
                                href="https://video-nerf.github.io/">Video-NeRF</a>, <a
                                href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a
                                href="https://neural-3d-video.github.io/">DyNeRF</a>
                        </p>
                        <p>
                            There are probably many more by the time you are reading this. Check out <a
                                href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF
                                papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's
                                curated list of NeRF papers</a>.
                        </p>
                    </div>
                </div>
            </div> -->
            <!--/ Concurrent Work. -->

        </div>
    </section>


    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@incollection{LabelAnything,
  title={Label Anything: Multi-Class Few-Shot Semantic Segmentation with Visual Prompts},
  author={Pasquale De Marinis, Nicola Fanelli, Raffaele Scaringi, Emanuele Colonna, Giuseppe Fiameni, Gennaro Vessio and Giovanna Castellano},
  booktitle={ECAI 2025},
  year={2025},
  note={in press}
}</code></pre>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="content has-text-centered">
                <a class="icon-link" href="./static/videos/nerfies_paper.pdf">
                    <i class="fas fa-file-pdf"></i>
                </a>
                <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
                    <i class="fab fa-github"></i>
                </a>
            </div>
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p>
                            This means you are free to borrow the <a
                                href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
                            we just ask that you link back to this page in the footer.
                            Please remember to remove the analytics code included in the header of the website which
                            you do not want on your website.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>


    <script src="https://cdn.jsdelivr.net/npm/swiper@11/swiper-bundle.min.js"></script>
    <script src="./static/js/swiper.js"></script>

</body>

</html>